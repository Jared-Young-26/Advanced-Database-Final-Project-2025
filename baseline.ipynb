{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f4ef97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "#   ADVANCED DATABASE PROJECT – DIABETES INDICATOR ANALYSIS\n",
    "#   CSV vs SQL vs Mongita PERFORMANCE + BASIC ML CLASSIFICATION\n",
    "# ================================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, confusion_matrix, classification_report\n",
    "from sklearn import svm\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebdf876b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "#  0. Download Dataset from Kaggle\n",
    "# ================================================================\n",
    "\n",
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"mohankrishnathalla/diabetes-health-indicators-dataset\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd92f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "#  1. LOAD DATA (CSV)\n",
    "# ================================================================\n",
    "\n",
    "CSV_PATH = \"diabetes_dataset.csv\"\n",
    "print(\"Loading CSV...\")\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42610ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# 2. BASIC STATISTICAL EXPLORATION\n",
    "# ================================================================\n",
    "\n",
    "print(\"\\n=== BASIC STATS ===\")\n",
    "print(df.describe().T)\n",
    "\n",
    "print(\"\\n=== CLASS DISTRIBUTION ===\")\n",
    "print(df[\"diagnosed_diabetes\"].value_counts(normalize=True))\n",
    "\n",
    "# Visualize a few correlations\n",
    "numeric_df = df.select_dtypes(include=[np.number])\n",
    "plt.figure(figsize=(12,10))\n",
    "plt.imshow(numeric_df.corr(), cmap='coolwarm')\n",
    "plt.colorbar()\n",
    "plt.title(\"Correlation Heatmap\")\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a442a449",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# 3. CSV QUERY TIMING\n",
    "# ================================================================\n",
    "\n",
    "def time_csv_query(query_func, name):\n",
    "    start = time.perf_counter()\n",
    "    result = query_func()\n",
    "    end = time.perf_counter()\n",
    "    print(f\"{name} → {end-start:.6f} sec\")\n",
    "    return result\n",
    "\n",
    "print(\"\\n=== CSV QUERY PERFORMANCE ===\")\n",
    "\n",
    "q1 = time_csv_query(lambda: df[df[\"bmi\"] > 30], \"People with BMI > 30\")\n",
    "q2 = time_csv_query(lambda: df.groupby(\"age\").size(), \"Group by Age\")\n",
    "q3 = time_csv_query(lambda: df[(df[\"bmi\"] > 25) & (df[\"systolic_bp\"] > 130)], \"Filter BMI > 25 & SystolicBP > 130\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e37cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# 4. LOAD CSV INTO SQLITE\n",
    "# ================================================================\n",
    "\n",
    "SQLITE_DB = \"diabetes.db\"\n",
    "\n",
    "conn = sqlite3.connect(SQLITE_DB)\n",
    "df.to_sql(\"diabetes\", conn, if_exists=\"replace\", index=False)\n",
    "\n",
    "print(\"\\nDatabase created:\", SQLITE_DB)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6ac20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# 5. SQL QUERY TIMING (NO INDEX)\n",
    "# ================================================================\n",
    "\n",
    "def sql_query(query, name):\n",
    "    start = time.perf_counter()\n",
    "    result = pd.read_sql_query(query, conn)\n",
    "    end = time.perf_counter()\n",
    "    print(f\"{name} → {end-start:.6f} sec\")\n",
    "    return result\n",
    "\n",
    "print(\"\\n=== SQL QUERY PERFORMANCE (NO INDEX) ===\")\n",
    "\n",
    "# BMI > 30\n",
    "sql_query(\"SELECT * FROM diabetes WHERE bmi > 30;\", \"SQL BMI > 30\")\n",
    "\n",
    "# Group by age\n",
    "sql_query(\"SELECT age, COUNT(*) FROM diabetes GROUP BY age;\", \"SQL group by age\")\n",
    "\n",
    "# Derived HighBP condition (systolic ≥130 OR diastolic ≥80)\n",
    "sql_query(\"\"\"\n",
    "    SELECT * \n",
    "    FROM diabetes \n",
    "    WHERE bmi > 25 \n",
    "      AND (systolic_bp >= 130 OR diastolic_bp >= 80);\n",
    "\"\"\", \n",
    "\"SQL BMI > 25 & High BP Condition\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e03d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# 6. CREATE INDEXES + RE-TIME QUERIES\n",
    "# ================================================================\n",
    "\n",
    "print(\"\\n=== CREATING INDEXES ===\")\n",
    "\n",
    "# Correct columns for THIS dataset\n",
    "conn.execute(\"CREATE INDEX IF NOT EXISTS idx_bmi ON diabetes(bmi);\")\n",
    "conn.execute(\"CREATE INDEX IF NOT EXISTS idx_age ON diabetes(age);\")\n",
    "\n",
    "# Derived high blood pressure index:\n",
    "# Use systolic_bp and diastolic_bp\n",
    "conn.execute(\"CREATE INDEX IF NOT EXISTS idx_bp ON diabetes(systolic_bp, diastolic_bp);\")\n",
    "\n",
    "conn.commit()\n",
    "\n",
    "print(\"\\n=== SQL QUERY PERFORMANCE (WITH INDEX) ===\")\n",
    "\n",
    "# Query 1\n",
    "sql_query(\"SELECT * FROM diabetes WHERE bmi > 30;\", \n",
    "          \"Indexed SQL bmi > 30\")\n",
    "\n",
    "# Query 2\n",
    "sql_query(\"SELECT age, COUNT(*) FROM diabetes GROUP BY age;\", \n",
    "          \"Indexed SQL group by age\")\n",
    "\n",
    "# Query 3 (derived \"HighBP\")\n",
    "sql_query(\"\"\"\n",
    "    SELECT * \n",
    "    FROM diabetes \n",
    "    WHERE bmi > 25\n",
    "      AND (systolic_bp >= 130 OR diastolic_bp >= 80);\n",
    "\"\"\",\n",
    "\"Indexed SQL bmi > 25 & High BP condition\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79072129",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# 7. VIEW QUERY PLANS\n",
    "# ================================================================\n",
    "\n",
    "print(\"\\n=== QUERY PLANS ===\")\n",
    "\n",
    "plans = [\n",
    "    # Query 1: BMI > 30\n",
    "    \"EXPLAIN QUERY PLAN SELECT * FROM diabetes WHERE bmi > 30;\",\n",
    "\n",
    "    # Query 2: group by age\n",
    "    \"EXPLAIN QUERY PLAN SELECT age, COUNT(*) FROM diabetes GROUP BY age;\",\n",
    "\n",
    "    # Query 3: derived high blood pressure condition\n",
    "    \"\"\"\n",
    "    EXPLAIN QUERY PLAN\n",
    "    SELECT *\n",
    "    FROM diabetes\n",
    "    WHERE bmi > 25\n",
    "      AND (systolic_bp >= 130 OR diastolic_bp >= 80);\n",
    "    \"\"\"\n",
    "]\n",
    "\n",
    "for p in plans:\n",
    "    print(\"\\n\", p)\n",
    "    print(pd.read_sql_query(p, conn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2587ad69",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d84dda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# 8. MONGITA\n",
    "# ================================================================\n",
    "from mongita import MongitaClientDisk\n",
    "\n",
    "client = MongitaClientDisk()\n",
    "db = client['mongo_diabetes']  # Use your database name\n",
    "collection = db['diabetes']  # Use your collection name\n",
    "\n",
    "\n",
    "data_dict = df.head(100).to_dict('records')\n",
    "\n",
    "collection.insert_many(data_dict)\n",
    "\n",
    "\n",
    "def mongita_query(mongo_query, name):\n",
    "    start = time.perf_counter()\n",
    "    \n",
    "    # Perform query\n",
    "    result = list(collection.find(mongo_query))  # Get results as a list of documents\n",
    "    \n",
    "    end = time.perf_counter()\n",
    "    print(f\"{name} → {end-start:.6f} sec\")\n",
    "\n",
    "\n",
    "mongo_query_1 = {\"bmi\": {\"$gt\": 30}}\n",
    "mongo_query_2 = {\"$group\": {\"_id\": \"$age\", \"count\": {\"$sum\": 1}}}  # Group by age\n",
    "mongo_query_3 = {\n",
    "    \"bmi\": {\"$gt\": 25},\n",
    "    \"$or\": [\n",
    "        {\"systolic_bp\": {\"$gte\": 130}},\n",
    "        {\"diastolic_bp\": {\"$gte\": 80}}\n",
    "    ]\n",
    "}\n",
    "\n",
    "mongita_query(mongo_query_1, \"Mongita BMI: First Run\")\n",
    "mongita_query(mongo_query_2, \"Mongita Group by Age: First Run\")\n",
    "mongita_query(mongo_query_3, \"Mongita BMI > 25 & High BP: First Run\")\n",
    "\n",
    "collection.create_index([(\"bmi\", 1)])  # Ascending index on 'bmi'\n",
    "collection.create_index([(\"age\", 1)])  # Ascending index on 'age'\n",
    "# Mongita does not support compound indexs\n",
    "\n",
    "print(\"\")\n",
    "mongita_query(mongo_query_1, \"Mongita BMI: Indexed First Run\")\n",
    "mongita_query(mongo_query_2, \"Mongita Group by Age: Indexed First Run\")\n",
    "\n",
    "curr = collection.find({})\n",
    "svm_data = list(curr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4b417f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# 9. BASIC CLASSIFICATION (LOGISTIC REGRESSION)\n",
    "# ================================================================\n",
    "\n",
    "print(\"\\n=== LOGISTIC REGRESSION MODEL ===\")\n",
    "\n",
    "# Correct target column for THIS dataset\n",
    "target = \"diagnosed_diabetes\"\n",
    "\n",
    "# Split features and target\n",
    "X = df.drop(columns=[target])\n",
    "y = df[target]\n",
    "\n",
    "# Convert all categorical columns into numeric dummy variables\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "# Standardize all numeric features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Logistic Regression model\n",
    "model_lr = LogisticRegression(max_iter=500)   # increase max_iter for stability\n",
    "model_lr.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "preds = model_lr.predict(X_test)\n",
    "\n",
    "# Performance metrics\n",
    "print(\"Accuracy:\", accuracy_score(y_test, preds))\n",
    "print(\"Precision:\", precision_score(y_test, preds))\n",
    "print(\"Recall:\", recall_score(y_test, preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c82a5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# 10. SIMPLE NEURAL NETWORK CLASSIFIER\n",
    "# ================================================================\n",
    "\n",
    "print(\"\\n=== NEURAL NETWORK CLASSIFIER ===\")\n",
    "\n",
    "# The neural network uses the already preprocessed:\n",
    "# X_train, X_test, y_train, y_test\n",
    "# created in Section 8 after one-hot encoding + scaling.\n",
    "\n",
    "nn = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dropout(0.3),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(1, activation='sigmoid')  # binary classification output\n",
    "])\n",
    "\n",
    "nn.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "history = nn.fit(\n",
    "    X_train, \n",
    "    y_train, \n",
    "    epochs=10, \n",
    "    validation_split=0.2, \n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "loss, acc = nn.evaluate(X_test, y_test)\n",
    "print(f\"\\nNN Accuracy: {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f116833",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# 11. SVM\n",
    "# ================================================================\n",
    "X_test, y_test, y_train, y_test\n",
    "model = svm.SVC(kernel='linear')\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\\n\", cm)\n",
    "\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0fa803",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# 12. FINAL NOTEBOOK SUMMARY\n",
    "# ================================================================\n",
    "\n",
    "print(\"\\n=== PROJECT SUMMARY ===\")\n",
    "print(\"1. Loaded CSV (no indexing) and ran queries.\")\n",
    "print(\"2. Loaded data into SQLite.\")\n",
    "print(\"3. Timed SQL queries with and without indexes.\")\n",
    "print(\"4. Compared EXPLAIN QUERY PLAN results.\")\n",
    "print(\"5. Performed basic statistical analysis.\")\n",
    "print(\"6. Trained Logistic Regression classifier.\")\n",
    "print(\"7. Trained small Neural Network classifier.\")\n",
    "print(\"\\nNotebook complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
